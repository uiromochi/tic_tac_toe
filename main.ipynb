{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"2d57hNOYLJ2N"},"outputs":[],"source":["import numpy as np\n","from numpy import random"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gNBQvMgRCh2G"},"outputs":[],"source":["class QLearningAgent:\n","    def __init__(self, n_state=3**9, n_action=9, alpha=0.5, gamma=0.99):\n","        self.n_state = n_state\n","        self.n_action = n_action\n","        self.alpha = alpha\n","        self.gamma = gamma\n","        self.qtable = np.random.uniform(low=-1,high=1,size=(self.n_state, self.n_action))\n","\n","    # Q-learningでQテーブルを更新\n","    def update_qtable(self, state, action, reward, next_state):\n","        self.qtable[state,action] += self.alpha*(reward + self.gamma*self.qtable[next_state].max() - self.qtable[state,action])\n","\n","    # Q値が最大の行動を選択\n","    def get_greedy_action(self, state):\n","        return self.qtable[state].argmax()\n","\n","    # εの確率でランダムに行動を選択\n","    def get_action(self, state, episode):\n","        epsilon = 0.7 * (1/(episode+1))\n","        if epsilon <= np.random.uniform(0,1):\n","            action = self.get_greedy_action(state)\n","        else:\n","            action = -1\n","        return action\n"]},{"cell_type":"markdown","metadata":{},"source":["done\n","\n","0: 空きマスがあり，勝敗もついていない（続行）\n","\n","1: 勝敗がついている\n","\n","2: 空きマスがなく，勝敗がついていない\n","\n","-1: すでに埋まっているマスを選択（違反）"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"v24bN4nW5Pls"},"outputs":[],"source":["class tic_tac_toe:\n","\n","    def __init__(self):\n","        self.idx = 0\n","        self.board = np.zeros(9, dtype=int)\n","\n","    def reset(self, done):\n","        if done != 0:\n","            self.idx = 0\n","            self.board[:] = 0\n","\n","    # ボードの様子を描画\n","    def draw(self):\n","        print(f\"idx: {self.idx}\")\n","        for i in range(3):\n","            print()\n","            for j in range(3):\n","                if self.board[3*i+j] == 1:\n","                    print(\" O \", end=\"\")\n","                elif self.board[3*i+j] == 2:\n","                    print(\" X \", end=\"\")\n","                else:\n","                    print(\" * \", end=\"\")\n","            print()\n","\n","    # 新しいマークを追加\n","    def step(self, pos):\n","        # すでに置かれている\n","        if self.board[pos] != 0:\n","            done = -1\n","            return done\n","\n","        self.idx += 1\n","        self.board[pos] = 2 - self.idx%2\n","        done = self.judge()\n","        return done\n","\n","    def random(self):\n","        pos = random.choice(np.where(self.board == 0)[0])\n","        self.idx += 1\n","        self.board[pos] = 2 - self.idx%2\n","\n","    def judge(self):\n","        for patt in [[0,1,2],[3,4,5],[6,7,8],[0,3,6],[1,4,7],[2,5,8],[0,4,8],[2,4,6]]:\n","            if np.all(self.board[patt] == 2 - self.idx%2):\n","                done = 1\n","                break\n","        else:\n","            done = 2 if self.idx == 9 else 0\n","        return done\n"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"KYtl6FCw49Zg"},"outputs":[],"source":["game = tic_tac_toe()\n","agent = QLearningAgent()\n"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["idx: 0\n","\n"," *  *  * \n","\n"," *  *  * \n","\n"," *  *  * \n","idx: 1\n","\n"," *  *  * \n","\n"," *  *  * \n","\n"," *  O  * \n","idx: 2\n","\n"," *  *  * \n","\n"," *  *  * \n","\n"," *  O  X \n","idx: 3\n","\n"," *  *  O \n","\n"," *  *  * \n","\n"," *  O  X \n","idx: 4\n","\n"," X  *  O \n","\n"," *  *  * \n","\n"," *  O  X \n","idx: 5\n","\n"," X  *  O \n","\n"," *  *  * \n","\n"," O  O  X \n","idx: 6\n","\n"," X  *  O \n","\n"," X  *  * \n","\n"," O  O  X \n","idx: 7\n","\n"," X  O  O \n","\n"," X  *  * \n","\n"," O  O  X \n","idx: 8\n","\n"," X  O  O \n","\n"," X  *  X \n","\n"," O  O  X \n","idx: 9\n","\n"," X  O  O \n","\n"," X  O  X \n","\n"," O  O  X \n","tic-tac-toe end\n"]}],"source":["game.reset(-1)\n","game.draw()\n","for _ in range(9):\n","    game.random()\n","    game.draw()\n","    if game.judge():\n","        print(\"tic-tac-toe end\")\n","        break\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hd3n7xflMM9M"},"outputs":[],"source":["# 各種設定\n","num_episode = 1200  # 学習エピソード数\n","penalty = 10  # 途中でエピソードが終了したときのペナルティ\n","\n","# ログ\n","episode_rewards = []\n","max_steps = (game.n_row) * (game.n_column)  # エピソードの最大ステップ数\n","\n","for episode in range(num_episode):\n","    game.reset()\n","    episode_reward = 0\n","\n","    for t in range(max_steps):\n","        action = agent.get_action(state, episode)  #  行動を選択\n","        next_state, reward, done, _ = game.step(action)\n","        # もしエピソードの途中で終了してしまったらペナルティを加える\n","        if done and t < max_steps - 1:\n","            reward = - penalty\n","        episode_reward += reward\n","        agent.update_qtable(state, action, reward, next_state)  # Q値の表を更新\n","        state = next_state\n","        if done:\n","            break\n","\n","    episode_rewards.append(episode_reward)\n","    if episode % 50 == 0:\n","        print(\"Episode %d finished | Episode reward %f\" % (episode, episode_reward))\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNWPdvvhSXz51EtxDB1AxBS","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":0}
